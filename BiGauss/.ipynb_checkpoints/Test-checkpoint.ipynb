{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nInputs\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from icecube import icetray, dataio, dataclasses, simclasses, clsim\n",
    "from icecube.icetray import I3Units, OMKey, I3Frame\n",
    "from icecube.dataclasses import ModuleKey\n",
    "from os.path import expandvars\n",
    "import scipy.constants as spc\n",
    "import scipy as sc\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import argparse\n",
    "from scipy import stats\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats.distributions import chi2\n",
    "\n",
    "import scipy\n",
    "\n",
    "'''\n",
    "Inputs\n",
    "'''\n",
    "#parser = argparse.ArgumentParser(description = \"Takes I3Photons from step2 of the simulations and generates DOM hits\")\n",
    "#parser.add_argument('-i', '--infile', dest = 'infile', help= 'input file and path')\n",
    "#parser.add_argument('-o', '--outfile', dest = 'outfile', help= 'output file and path')\n",
    "#args = parser.parse_args()\n",
    "\n",
    "#args.input = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Functions\n",
    "'''\n",
    "\n",
    "def gaussian(x, pos, wid, amp):\n",
    "    y = amp*np.exp(-4*np.log(2)*((x-pos)/(wid))**2)\n",
    "    return y\n",
    "\n",
    "def biGauss(x, pos, wid, r, amp):\n",
    "    mask = x < pos\n",
    "\n",
    "    y_all = ([])\n",
    "    for i in range(0, len(mask)):\n",
    "\n",
    "        if mask[i] == True:\n",
    "            m = 1\n",
    "            nm = 0\n",
    "        else:\n",
    "            m = 0\n",
    "            nm = 1\n",
    "        if r != 0:\n",
    "            y1 = gaussian(x[i],pos,r*wid/(r+1),amp)*m\n",
    "            y2 = gaussian(x[i],pos,wid/(r+1),amp)*nm\n",
    "            y = y1 + y2\n",
    "        else:\n",
    "            y = gaussian(x[i],pos,wid, amp)*nm\n",
    "\n",
    "        y_all = np.append(y_all, y)\n",
    "    return y_all\n",
    "\n",
    "def double_peak(x, pos1, wid1, r1, amp1, pos2, wid2, r2, amp2):\n",
    "    b1 = biGauss(x, pos1, wid1, r1, amp1)\n",
    "    b2 = biGauss(x, pos2, wid2, r2, amp2)\n",
    "    b = np.append(b1, b2)\n",
    "    return b1+b2\n",
    "\n",
    "def log_likelihood_biGauss(theta, n, x):\n",
    "    pos, wid, r, amp = theta\n",
    "    model = biGauss(x, pos, wid, r, amp)\n",
    "    L = np.log(scipy.special.factorial(n)) + model - (n*np.log(model))\n",
    "    return np.sum(L)\n",
    "\n",
    "def log_likelihood_doublePeak(theta, n, x):\n",
    "    pos1, wid1, r1, amp1, pos2, wid2, r2, amp2 = theta\n",
    "    model = double_peak(x, pos1, wid1, r1, amp1, pos2, wid2, r2, amp2)\n",
    "    L = np.log(scipy.special.factorial(n)) + model - (n*np.log(model))\n",
    "    return np.sum(L)\n",
    "\n",
    "def likelihood_ratio_doublePeak(x, n, pos1, wid1, r1, amp1, pos2, wid2, r2, amp2):\n",
    "    model = double_peak(x, pos1, wid1, r1, amp1, pos2, wid2, r2, amp2)\n",
    "    val = model - n + (n*np.log(n/model))\n",
    "    #print('log - ', n/model, 'n - ', n)\n",
    "    return np.sum(val)\n",
    "\n",
    "def likelihood_ratio_biGauss(x, n, pos, wid, r, amp):\n",
    "    model = biGauss(x, pos, wid, r, amp)\n",
    "    val = model - n + (n*np.log(n/model))\n",
    "    #print('log - ', n/model, 'n - ', n)\n",
    "    return np.sum(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded geometry\n"
     ]
    }
   ],
   "source": [
    "gcd_file = dataio.I3File('/home/users/akatil/P-ONE/GCD_files/PONE_Phase1.i3.gz')\n",
    "cframe = gcd_file.pop_frame()\n",
    "geometry = cframe[\"I3Geometry\"]\n",
    "omgeo = geometry.omgeo\n",
    "print('loaded geometry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def likelihoodfit():\n",
    "\n",
    "    print('LikelihoodFit')\n",
    "    tau_timeDiff = ([])\n",
    "    tau_pVal = ([])\n",
    "    tau_LRR = ([])\n",
    "    tau_wid1_ratio = ([])\n",
    "    tau_wid2_ratio = ([])\n",
    "    tau_amp1_ratio = ([])\n",
    "    tau_amp2_ratio = ([])\n",
    "\n",
    "    e_timeDiff = ([])\n",
    "    e_pVal = ([])\n",
    "    e_LRR = ([])\n",
    "    e_wid1_ratio = ([])\n",
    "    e_wid2_ratio = ([])\n",
    "    e_amp1_ratio = ([])\n",
    "    e_amp2_ratio = ([])\n",
    "\n",
    "    tau_wid_ratio_dp = ([])\n",
    "    e_wid_ratio_dp = ([])\n",
    "    tau_amp_ratio_dp = ([])\n",
    "    e_amp_ratio_dp = ([])\n",
    "\n",
    "    #print('FILE NUMBER - ', str(args.infile))\n",
    "    #file = dataio.I3File('/data/p-one/akatil/step_4_medium_water/NuTau_NuE_20Events/step_4_'+str(i)+'_medium_water_custom_mDOM_noise.i3.gz')\n",
    "    file = dataio.I3File(str(args.infile))\n",
    "\n",
    "    f = 1\n",
    "\n",
    "    #txt_file = open(\"/data/p-one/akatil/analysis/25_30/files_greater_than_100.txt\", \"a\")\n",
    "\n",
    "    for frame in file:\n",
    "        #print('frame num - ', f)\n",
    "        mctree = frame[\"I3MCTree\"]\n",
    "        primary = mctree.primaries\n",
    "        lepton = dataclasses.I3MCTree.first_child(mctree, primary[0].id)\n",
    "\n",
    "        mcpeMap = frame['MCPESeriesMap']\n",
    "        noiseMap = frame['NoiseSeriesMap']\n",
    "\n",
    "        for omkey in mcpeMap.keys():\n",
    "            oKey = omgeo.get(omkey)\n",
    "\n",
    "            '''\n",
    "            Obtaining the timeList\n",
    "            '''\n",
    "            noise_mcpeList = noiseMap[omkey]\n",
    "            noise_timeList = np.array([mcpe.time for mcpe in noise_mcpeList])\n",
    "            mcpeList = mcpeMap[omkey]\n",
    "            timeList = np.array([mcpe.time for mcpe in mcpeList])\n",
    "            tot_timeList = np.append(timeList, noise_timeList)\n",
    "\n",
    "\n",
    "            '''\n",
    "            Removing DOMs with hits less than 250 Hits\n",
    "            '''\n",
    "            if len(tot_timeList) < 250:\n",
    "                continue\n",
    "\n",
    "\n",
    "            '''\n",
    "            Calculating the mean and removing the tails\n",
    "            '''\n",
    "\n",
    "            timeList = timeList[timeList < min(timeList)+30]\n",
    "\n",
    "            mean_physicsHits = timeList.mean()\n",
    "            mean_tot = tot_timeList.mean()\n",
    "\n",
    "            select_time = tot_timeList[(tot_timeList > mean_physicsHits-50) & (tot_timeList < mean_physicsHits+50)]\n",
    "            new_mean = select_time.mean()\n",
    "\n",
    "            bins = np.arange(min(select_time), max(select_time), 1)\n",
    "            max_hitTimes = select_time[(select_time > (new_mean-50))&(select_time < (new_mean+50))]\n",
    "\n",
    "            z = stats.zscore(max_hitTimes)\n",
    "\n",
    "            #using zscore to remove the effect of outliers from the analysis]\n",
    "            max_hitTimes = max_hitTimes[(z>-1.2)&(z < 1.2)]\n",
    "            new_mean = max_hitTimes.mean()\n",
    "            timestamps = max_hitTimes - new_mean\n",
    "            final_mean = timestamps.mean()\n",
    "\n",
    "            num_photons = len(max_hitTimes[max_hitTimes>0])\n",
    "\n",
    "            if len(max_hitTimes) < 250:\n",
    "                continue\n",
    "\n",
    "            #if np.log10(num_photons) >= 3.0 or np.log10(num_photons) < 2.5:\n",
    "                #continue\n",
    "\n",
    "            '''\n",
    "            Histogramming the data from simulation\n",
    "            '''\n",
    "\n",
    "            bins = np.arange(min(timestamps), max(timestamps), 1)\n",
    "            num, bin_edges = np.histogram(timestamps, bins=bins)\n",
    "            bin_centers = (bin_edges[:-1]+bin_edges[1:])/2\n",
    "\n",
    "            #print('LOG LIKELIHOOD')\n",
    "\n",
    "            '''\n",
    "            Removing DOMs that don't have less than 8 non zero bins\n",
    "            '''\n",
    "            if len(num[num>0]) <= 8:\n",
    "                continue\n",
    "\n",
    "\n",
    "\n",
    "            '''\n",
    "            Fitting bifurcated Gaussian and double bifurcated gaussian to the mcpe hit time distributions\n",
    "            for both tau and electron.\n",
    "            '''\n",
    "\n",
    "            nll = lambda *args: log_likelihood_biGauss(*args)\n",
    "            initial_biGauss = np.array([final_mean, 50, 5, max(num)])\n",
    "            #bnds_biGauss = ((min(bin_centers), mean_timeArrival), (0, 20), (0, 2), (0, max(num)), (mean_timeArrival, max(bin_centers)), (0, 20), (0, 2), (0, max(num)))\n",
    "\n",
    "            #print(len(num), len(initial_biGauss), initial_biGauss)\n",
    "            bnds_biGauss = ((min(bin_centers), max(bin_centers)), (0, 110), (0, 10), (0, 1e6))\n",
    "            soln_biGauss = minimize(log_likelihood_biGauss, initial_biGauss, args=(num, bin_centers),\n",
    "                                    method='Powell', bounds = bnds_biGauss)\n",
    "\n",
    "            nll = lambda *args: log_likelihood_doublePeak(*args)\n",
    "            initial_doublePeak = np.array([min(bin_centers), 20, 1, max(num), final_mean, 20, 1, max(num)])\n",
    "            bnds_doublePeak = ((min(bin_centers), final_mean), (0, 110), (0, 10), (0, 1e6),\n",
    "                               (final_mean, max(bin_centers)), (0, 110), (0, 10), (0,1e6))\n",
    "            soln_doublePeak = minimize(log_likelihood_doublePeak, initial_doublePeak, args=(num, bin_centers),\n",
    "                                       method='Powell',bounds=bnds_doublePeak)\n",
    "\n",
    "            '''\n",
    "            Removing DOMs whose minimization is not successful\n",
    "            '''\n",
    "            #if soln_biGauss.success == False or soln_doublePeak.success == False:\n",
    "                #print('Removing DOMs whose minimization is not successful')\n",
    "                #continue\n",
    "\n",
    "            '''\n",
    "            Calculating the Likelihood ratio for bifurcated gaussian and double double bifurcated gaussian\n",
    "            '''\n",
    "            LR_biGauss = likelihood_ratio_biGauss(bin_centers[num>0], num[num>0], soln_biGauss.x[0],\n",
    "                                             soln_biGauss.x[1], soln_biGauss.x[2], soln_biGauss.x[3])\n",
    "            LR_doublePeak = likelihood_ratio_doublePeak(bin_centers[num>0], num[num>0], soln_doublePeak.x[0], soln_doublePeak.x[1],\n",
    "                                             soln_doublePeak.x[2], soln_doublePeak.x[3], soln_doublePeak.x[4],\n",
    "                                             soln_doublePeak.x[5], soln_doublePeak.x[6], soln_doublePeak.x[7])\n",
    "\n",
    "\n",
    "            '''\n",
    "            Calculating the p-value using the likelihood ratio\n",
    "            '''\n",
    "            pVal_biGauss = chi2.sf(LR_biGauss, len(num) - 4)\n",
    "            pVal_doublePeak = chi2.sf(LR_doublePeak, len(num) - 8)\n",
    "\n",
    "            if pVal_biGauss != pVal_biGauss:\n",
    "                print('BiGauss is not well defined - ', str(lepton.type))\n",
    "                print('Minimisation - ', soln_biGauss.success)\n",
    "                print('Degrees of Freedom - ', len(num) - 4)\n",
    "                print('Log Likelihood - ', LR_biGauss)\n",
    "            if pVal_doublePeak != pVal_doublePeak:\n",
    "                print('double peak is not well defined - ', str(lepton.type))\n",
    "                print('Minimisation - ', soln_doublePeak.success)\n",
    "                print('Degrees of Freedom - ', len(num) - 8)\n",
    "                print('Log Likelihood - ', LR_doublePeak)\n",
    "\n",
    "            '''\n",
    "            (x, y) values for the fit\n",
    "            '''\n",
    "            x = np.linspace(min(bin_centers), max(bin_centers), 1000)\n",
    "            #x = np.linspace(0, max(bin_centers)+1e5, 1000)\n",
    "            y_biGauss = biGauss(x, soln_biGauss.x[0],\n",
    "                                            soln_biGauss.x[1], soln_biGauss.x[2], soln_biGauss.x[3])\n",
    "            y_doublePeak = double_peak(x, soln_doublePeak.x[0], soln_doublePeak.x[1],\n",
    "                                            soln_doublePeak.x[2], soln_doublePeak.x[3], soln_doublePeak.x[4],\n",
    "                                            soln_doublePeak.x[5], soln_doublePeak.x[6], soln_doublePeak.x[7])\n",
    "\n",
    "            '''\n",
    "            Calculating the time difference and p-value ratio of bigauss and double peak\n",
    "            '''\n",
    "            timeDifference_doublePeak = soln_doublePeak.x[4] - soln_doublePeak.x[0]\n",
    "            pVal_ratio = pVal_doublePeak/pVal_biGauss\n",
    "            LRR = LR_doublePeak/LR_biGauss\n",
    "            wid1_ratio = soln_doublePeak.x[1]/soln_biGauss.x[1]\n",
    "            wid2_ratio = soln_doublePeak.x[5]/soln_biGauss.x[1]\n",
    "            amp1_ratio = soln_doublePeak.x[3]/soln_biGauss.x[3]\n",
    "            amp2_ratio = soln_doublePeak.x[7]/soln_biGauss.x[3]\n",
    "            wid1_wid2 = soln_doublePeak.x[1]/soln_doublePeak.x[5]\n",
    "            amp1_amp2 = soln_doublePeak.x[3]/soln_doublePeak.x[7]\n",
    "\n",
    "\n",
    "\n",
    "            '''\n",
    "            Removing terrible fits\n",
    "            '''\n",
    "            if abs(timeDifference_doublePeak) > 100:\n",
    "                print('*****----------timeDifference > 100----------********')\n",
    "                #print(str(args.infile)+'----->', timeDifference_doublePeak)\n",
    "                #txt_file.write('File - '+str(args.infile)+' - Frame Number - '+str(f)+' - OMKey - '+str(omkey)+ ' - Time Difference - '+str(timeDifference_doublePeak)+'-\\n')\n",
    "                #continue\n",
    "\n",
    "            amp1 = soln_doublePeak.x[3]\n",
    "            amp2 = soln_doublePeak.x[7]\n",
    "            if amp1/amp2 < 1/4 and amp1/amp2 > 4:\n",
    "                print('Removing terrible fits')\n",
    "                continue\n",
    "\n",
    "            if amp1 < 0 or amp2 < 0:\n",
    "                print('Error in amp')\n",
    "                continue\n",
    "\n",
    "            print('Reached Here')\n",
    "\n",
    "\n",
    "            '''\n",
    "            plot mcpe time distributions obtained using simulations and the fits\n",
    "            '''\n",
    "            #plt.figure(figsize=(10,9))\n",
    "            #_ = plt.hist(timestamps, bins=bins, histtype='step')\n",
    "            #plt.title(str(lepton.type))\n",
    "            #plt.plot(x, y_biGauss, '--', c = 'r')\n",
    "            #plt.plot(x, y_doublePeak, '--', c = 'k')\n",
    "            #plt.axvline(final_mean, c = 'b')\n",
    "\n",
    "\n",
    "            '''\n",
    "            Separating the time difference calculated above and appending the values\n",
    "            '''\n",
    "\n",
    "            '''\n",
    "            Tau\n",
    "            '''\n",
    "            if lepton.type == 15 or lepton.type == -15:\n",
    "                tau_timeDiff = np.append(tau_timeDiff, timeDifference_doublePeak)\n",
    "                tau_pVal = np.append(tau_pVal, pVal_ratio)\n",
    "                tau_LRR = np.append(tau_LRR, LRR)\n",
    "                tau_wid1_ratio = np.append(tau_wid1_ratio, wid1_ratio)\n",
    "                tau_wid2_ratio = np.append(tau_wid2_ratio, wid2_ratio)\n",
    "                tau_amp1_ratio = np.append(tau_amp1_ratio, amp1_ratio)\n",
    "                tau_amp2_ratio = np.append(tau_amp2_ratio, amp2_ratio)\n",
    "\n",
    "                tau_wid_ratio_dp = np.append(tau_wid_ratio_dp, wid1_wid2)\n",
    "                tau_amp_ratio_dp = np.append(tau_amp_ratio_dp, amp1_amp2)\n",
    "                #plt.title('E')\n",
    "\n",
    "            '''\n",
    "            Electron and Neutral Current\n",
    "            '''\n",
    "\n",
    "            if lepton.type == 11 or lepton.type == -11 or lepton.type == 12 or lepton.type == -12 or lepton.type == 16 or lepton.type == -16:\n",
    "\n",
    "                e_timeDiff = np.append(e_timeDiff, timeDifference_doublePeak)\n",
    "                e_pVal = np.append(e_pVal, pVal_ratio)\n",
    "                e_LRR = np.append(e_LRR, LRR)\n",
    "                e_wid1_ratio = np.append(e_wid1_ratio, wid1_ratio)\n",
    "                e_wid2_ratio = np.append(e_wid2_ratio, wid2_ratio)\n",
    "                e_amp1_ratio = np.append(e_amp1_ratio, amp1_ratio)\n",
    "                e_amp2_ratio = np.append(e_amp2_ratio, amp2_ratio)\n",
    "\n",
    "                e_wid_ratio_dp = np.append(e_wid_ratio_dp, wid1_wid2)\n",
    "                e_amp_ratio_dp = np.append(e_amp_ratio_dp, amp1_amp2)\n",
    "\n",
    "            #print('P-VAL CALCULATED')\n",
    "\n",
    "        f = f+1\n",
    "\n",
    "    #txt_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
